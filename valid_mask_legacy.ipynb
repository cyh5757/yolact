{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e27a392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home/mbd1234/yolact\n"
     ]
    }
   ],
   "source": [
    "import os, sys, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ▶ 여기를 본인 환경에 맞게 바꾸세요.\n",
    "# os.chdir(\"/home/mbd1234/yolact\")  # 예시\n",
    "\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3d8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from data import cfg, set_cfg, set_dataset, COCODetection, MEANS\n",
    "from utils.augmentations import BaseTransform\n",
    "from yolact import Yolact\n",
    "from layers.output_utils import postprocess\n",
    "\n",
    "import eval as eval_script  # 평가 플래그 주입용\n",
    "\n",
    "# ▶ 본인이 쓰는 설정/체크포인트로 맞춰주세요.\n",
    "CFG_NAME = \"cell_yolact_im700_config\"   # 예: cell_yolact_im700_config\n",
    "DATASET_OVERRIDE = None                  # 보통 None\n",
    "CHECKPOINT = \"weights/cell_yolact_im700_86_1726_interrupt.pth\"  # 없으면 None로 두면 backbone init\n",
    "\n",
    "SPLIT = \"val\"       # 'train' or 'val'\n",
    "K = 3               # sanity probe에 사용할 이미지 수\n",
    "PROBE_SCORE_THR = 0.01\n",
    "\n",
    "EVAL_SCORE_THR = 0.05\n",
    "EVAL_TOP_K = 200\n",
    "EVAL_NMS = 0.5\n",
    "VALIDATION_SIZE = 200\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "def device():\n",
    "    return torch.device('cuda' if USE_CUDA else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "574f1d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "[DATA] split=val, len=10\n"
     ]
    }
   ],
   "source": [
    "set_cfg(CFG_NAME)\n",
    "if DATASET_OVERRIDE:\n",
    "    set_dataset(DATASET_OVERRIDE)\n",
    "\n",
    "def build_dataset(split: str):\n",
    "    if split == 'train':\n",
    "        ds = COCODetection(image_path=cfg.dataset.train_images,\n",
    "                           info_file=cfg.dataset.train_info,\n",
    "                           transform=BaseTransform(MEANS))\n",
    "    else:\n",
    "        ds = COCODetection(image_path=cfg.dataset.valid_images,\n",
    "                           info_file=cfg.dataset.valid_info,\n",
    "                           transform=BaseTransform(MEANS))\n",
    "    return ds\n",
    "\n",
    "dataset = build_dataset(SPLIT)\n",
    "print(f\"[DATA] split={SPLIT}, len={len(dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c553dcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Anchor/Level Configuration ===\n",
      "- cfg.num_classes: 2\n",
      "- cfg.max_size: 1024\n",
      "- pred_scales levels: 6 -> [[8], [16], [24], [48], [96], [192]]\n",
      "- pred_aspect_ratios levels: 6\n",
      "✅ 레벨 수 일치\n",
      "- backbone.selected_layers: [1, 2, 3] (len=3)\n"
     ]
    }
   ],
   "source": [
    "def check_anchor_config():\n",
    "    ok = True\n",
    "    bb = getattr(cfg, 'backbone', None)\n",
    "    if bb is None:\n",
    "        print(\"[ANCHOR] cfg.backbone 이 없습니다.\")\n",
    "        return False\n",
    "\n",
    "    ps = getattr(bb, 'pred_scales', None)\n",
    "    pa = getattr(bb, 'pred_aspect_ratios', None)\n",
    "\n",
    "    print(\"\\n=== Anchor/Level Configuration ===\")\n",
    "    print(\"- cfg.num_classes:\", getattr(cfg, \"num_classes\", None))\n",
    "    print(\"- cfg.max_size:\", getattr(cfg, \"max_size\", None))\n",
    "    if ps is not None:\n",
    "        print(f\"- pred_scales levels: {len(ps)} -> {ps}\")\n",
    "    else:\n",
    "        print(\"- pred_scales: None\")\n",
    "\n",
    "    if pa is not None:\n",
    "        print(f\"- pred_aspect_ratios levels: {len(pa)}\")\n",
    "    else:\n",
    "        print(\"- pred_aspect_ratios: None\")\n",
    "\n",
    "    if (ps is None) or (pa is None):\n",
    "        print(\"⚠️ pred_scales 또는 pred_aspect_ratios 가 없습니다.\")\n",
    "        return False\n",
    "\n",
    "    if len(ps) != len(pa):\n",
    "        print(\"❗ 레벨 수 불일치: pred_scales 와 pred_aspect_ratios 길이가 다릅니다.\")\n",
    "        ok = False\n",
    "    else:\n",
    "        print(\"✅ 레벨 수 일치\")\n",
    "\n",
    "    sel = getattr(bb, 'selected_layers', None)\n",
    "    if sel is not None:\n",
    "        print(f\"- backbone.selected_layers: {sel} (len={len(sel)})\")\n",
    "\n",
    "    return ok\n",
    "\n",
    "_ = check_anchor_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cd59c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Label Distribution Probe ===\n",
      "- sample #0: labels={0: 248}  (num_inst=248)\n",
      "- sample #1: labels={0: 78}  (num_inst=78)\n",
      "- sample #2: labels={0: 117, -1: 64}  (num_inst=181)\n",
      "- sample #3: labels={0: 299}  (num_inst=299)\n",
      "- sample #4: labels={0: 319}  (num_inst=319)\n",
      "==> Aggregated: {0: 1061, -1: 64} ; cfg.num_classes=2\n",
      "⚠️ 라벨 인덱스가 cfg.num_classes 범위를 벗어나요. (카테고리 id/라벨맵 의심)\n",
      "⚠️ 유효 클래스(1)가 보이지 않습니다. (COCO categories.id=1 권장)\n"
     ]
    }
   ],
   "source": [
    "def peek_label_distribution(ds, first_n=5):\n",
    "    print(\"\\n=== Label Distribution Probe ===\")\n",
    "    num_classes = getattr(cfg, \"num_classes\", None)\n",
    "    agg = Counter()\n",
    "    limit = min(first_n, len(ds))\n",
    "    for i in range(limit):\n",
    "        img, (tgt, gt_masks, num_crowd) = ds[i]\n",
    "        try:\n",
    "            cls = [int(x[-1]) for x in tgt]\n",
    "        except Exception:\n",
    "            cls = [int(tgt[j, -1].item()) for j in range(tgt.shape[0])]\n",
    "        cnt = Counter(cls)\n",
    "        agg.update(cnt)\n",
    "        print(f\"- sample #{i}: labels={dict(cnt)}  (num_inst={sum(cnt.values())})\")\n",
    "    print(f\"==> Aggregated: {dict(agg)} ; cfg.num_classes={num_classes}\")\n",
    "\n",
    "    # 휴리스틱 경고\n",
    "    if len(agg) == 0:\n",
    "        print(\"⚠️ GT 라벨이 비어 있거나 포맷이 다를 수 있습니다.\")\n",
    "    if num_classes is not None and any((c < 0 or c >= num_classes) for c in agg.keys()):\n",
    "        print(\"⚠️ 라벨 인덱스가 cfg.num_classes 범위를 벗어나요. (카테고리 id/라벨맵 의심)\")\n",
    "    if num_classes == 2:\n",
    "        # 배경 0, 유효 1 한 개만 기대\n",
    "        non_bg = [c for c in agg if c != 0]\n",
    "        if len(non_bg) > 1:\n",
    "            print(\"⚠️ 단일 클래스 문제인데 유효 클래스 라벨이 여러 개 감지됨 (categories.id/label_map 확인).\")\n",
    "        elif 1 not in agg and len(agg) > 0:\n",
    "            print(\"⚠️ 유효 클래스(1)가 보이지 않습니다. (COCO categories.id=1 권장)\")\n",
    "\n",
    "peek_label_distribution(dataset, first_n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e30499d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODEL] load_weights: weights/cell_yolact_im700_86_1726_interrupt.pth\n",
      "[PROTO] exists: False\n",
      "[GT MASK] dtype: uint8 min/max: 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def load_model_and_print_proto(ckpt_path=None, dev=None):\n",
    "    dev = dev or device()\n",
    "    model = Yolact().to(dev)\n",
    "    if ckpt_path and os.path.isfile(ckpt_path):\n",
    "        print(f\"[MODEL] load_weights: {ckpt_path}\")\n",
    "        model.load_weights(ckpt_path)\n",
    "    else:\n",
    "        print(\"[MODEL] init_weights from backbone\")\n",
    "        backbone_path = cfg.backbone.path\n",
    "        if not os.path.isabs(backbone_path):\n",
    "            backbone_path = os.path.join(\"weights\", backbone_path)\n",
    "        model.init_weights(backbone_path=backbone_path)\n",
    "    model.eval()\n",
    "\n",
    "    # 한 장 던져 proto 유무/shape 확인\n",
    "    if len(dataset) > 0:\n",
    "        img, (tgt, gt_masks, num_crowd) = dataset[0]\n",
    "        x = img.unsqueeze(0).to(dev)\n",
    "        preds = model(x)\n",
    "        proto = preds.get(\"proto\", None) if isinstance(preds, dict) else None\n",
    "        print(\"[PROTO] exists:\", proto is not None)\n",
    "        if proto is not None:\n",
    "            print(\"[PROTO] shape:\", tuple(proto.shape))\n",
    "        # GT 마스크 값 범위/형 확인\n",
    "        if hasattr(gt_masks, \"dtype\"):\n",
    "            print(\"[GT MASK] dtype:\", gt_masks.dtype,\n",
    "                  \"min/max:\", float(gt_masks.min()), float(gt_masks.max()))\n",
    "    model.train()\n",
    "    return model\n",
    "\n",
    "model = load_model_and_print_proto(CHECKPOINT, device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfe6b71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Postprocess Sanity Probe (k=3, score_thr=0.01) ===\n",
      "- sample #0: det=200, score[min,max]=(0.23720140755176544,0.965642511844635), classes={0: 200}\n",
      "- sample #1: det=200, score[min,max]=(0.1616656333208084,0.8309450745582581), classes={0: 200}\n",
      "- sample #2: det=200, score[min,max]=(0.20879216492176056,0.8090166449546814), classes={0: 200}\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def sanity_probe(model, ds, dev=None, k=3, score_thr=0.01):\n",
    "    dev = dev or device()\n",
    "    print(f\"\\n=== Postprocess Sanity Probe (k={k}, score_thr={score_thr}) ===\")\n",
    "    model.eval()\n",
    "    n = min(k, len(ds))\n",
    "    if n == 0:\n",
    "        print(\"⚠️ 데이터셋이 비어 있습니다.\")\n",
    "        return\n",
    "    for i in range(n):\n",
    "        img, _ = ds[i]\n",
    "        h, w = img.shape[1:]\n",
    "        x = img.unsqueeze(0).to(dev)\n",
    "        preds = model(x)\n",
    "        out = postprocess(preds, w, h, score_threshold=float(score_thr))\n",
    "        if out is None:\n",
    "            print(f\"- sample #{i}: det=0 (postprocess returned None)\")\n",
    "            continue\n",
    "        classes, scores, boxes, masks = out\n",
    "        d = len(scores)\n",
    "        smin = float(scores.min()) if d > 0 else None\n",
    "        smax = float(scores.max()) if d > 0 else None\n",
    "        ucls = Counter([int(c) for c in classes]) if d > 0 else {}\n",
    "        print(f\"- sample #{i}: det={d}, score[min,max]=({smin},{smax}), classes={dict(ucls)}\")\n",
    "\n",
    "sanity_probe(model, dataset, device(), k=K, score_thr=PROBE_SCORE_THR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9541a9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== One-Image Mask IoU Probe (idx=0, score_thr=0.1) ===\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "postprocess() got an unexpected keyword argument 'top_k'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(i == \u001b[32m0.0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ious):\n\u001b[32m     57\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m⚠️ 모든 샘플 IoU=0 → 마스크 정렬/크롭/스케일/포맷 문제 가능성 큼 (box는 가능).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43mprobe_one_image_mask_iou\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_thr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.yolaVenv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mprobe_one_image_mask_iou\u001b[39m\u001b[34m(model, ds, index, score_thr, top_k, dev)\u001b[39m\n\u001b[32m     23\u001b[39m x = img.unsqueeze(\u001b[32m0\u001b[39m).to(dev)\n\u001b[32m     24\u001b[39m preds = model(x)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m out = \u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscore_thr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo detections.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: postprocess() got an unexpected keyword argument 'top_k'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def quick_mask_iou(pred_mask, gt_mask):\n",
    "    \"\"\"\n",
    "    pred_mask, gt_mask: HxW (bool or {0,1}), 같은 크기로 가정\n",
    "    \"\"\"\n",
    "    pm = pred_mask.astype(np.bool_)\n",
    "    gm = gt_mask.astype(np.bool_)\n",
    "    inter = np.logical_and(pm, gm).sum()\n",
    "    union = np.logical_or(pm, gm).sum()\n",
    "    return (inter / union) if union > 0 else 0.0\n",
    "\n",
    "@torch.no_grad()\n",
    "def probe_one_image_mask_iou(model, ds, index=0, score_thr=0.1, top_k=5, dev=None):\n",
    "    dev = dev or device()\n",
    "    print(f\"\\n=== One-Image Mask IoU Probe (idx={index}, score_thr={score_thr}) ===\")\n",
    "    if index >= len(ds):\n",
    "        print(\"Index out of range.\")\n",
    "        return\n",
    "    img, (tgt, gt_masks, num_crowd) = ds[index]\n",
    "    H, W = img.shape[1:]\n",
    "    x = img.unsqueeze(0).to(dev)\n",
    "    preds = model(x)\n",
    "    out = postprocess(preds, W, H, score_threshold=float(score_thr), top_k=top_k)\n",
    "    if out is None:\n",
    "        print(\"No detections.\")\n",
    "        return\n",
    "    classes, scores, boxes, masks = out  # masks: [N, H, W] expected\n",
    "    print(f\"Detections: {len(scores)}\")\n",
    "\n",
    "    # GT 마스크가 [N,H,W] 텐서로 들어오는 포크가 많음\n",
    "    if isinstance(gt_masks, torch.Tensor):\n",
    "        gt_bin = (gt_masks.detach().cpu().float() > 0.5).numpy()\n",
    "        if gt_bin.ndim == 2:\n",
    "            gt_bin = gt_bin[None, ...]  # [1,H,W]\n",
    "    else:\n",
    "        gt_bin = np.asarray(gt_masks)\n",
    "        if gt_bin.ndim == 2:\n",
    "            gt_bin = gt_bin[None, ...]\n",
    "\n",
    "    # pred 상위 1~few개만 샘플 IoU\n",
    "    m = min(len(scores), gt_bin.shape[0], top_k)\n",
    "    if m == 0:\n",
    "        print(\"No comparable masks (either pred or gt is empty).\")\n",
    "        return\n",
    "\n",
    "    ious = []\n",
    "    for i in range(m):\n",
    "        pm = (masks[i].detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
    "        gm = gt_bin[i].astype(np.uint8) if i < gt_bin.shape[0] else gt_bin[0].astype(np.uint8)\n",
    "        iou = quick_mask_iou(pm, gm)\n",
    "        ious.append(iou)\n",
    "        print(f\"  - pair #{i}: IoU={iou:.4f}\")\n",
    "\n",
    "    if all(i == 0.0 for i in ious):\n",
    "        print(\"⚠️ 모든 샘플 IoU=0 → 마스크 정렬/크롭/스케일/포맷 문제 가능성 큼 (box는 가능).\")\n",
    "\n",
    "probe_one_image_mask_iou(model, dataset, index=0, score_thr=0.1, top_k=5, dev=device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4cbeaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Inject eval.py flags ===\n",
      "--max_images=200, --score_threshold=0.05, --top_k=200, --nms_threshold=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--trained_model TRAINED_MODEL]\n",
      "                             [--top_k TOP_K] [--cuda CUDA]\n",
      "                             [--fast_nms FAST_NMS]\n",
      "                             [--cross_class_nms CROSS_CLASS_NMS]\n",
      "                             [--display_masks DISPLAY_MASKS]\n",
      "                             [--display_bboxes DISPLAY_BBOXES]\n",
      "                             [--display_text DISPLAY_TEXT]\n",
      "                             [--display_scores DISPLAY_SCORES] [--display]\n",
      "                             [--shuffle] [--ap_data_file AP_DATA_FILE]\n",
      "                             [--resume] [--max_images MAX_IMAGES]\n",
      "                             [--output_coco_json]\n",
      "                             [--bbox_det_file BBOX_DET_FILE]\n",
      "                             [--mask_det_file MASK_DET_FILE] [--config CONFIG]\n",
      "                             [--output_web_json] [--web_det_path WEB_DET_PATH]\n",
      "                             [--no_bar] [--display_lincomb DISPLAY_LINCOMB]\n",
      "                             [--benchmark] [--no_sort] [--seed SEED]\n",
      "                             [--mask_proto_debug] [--no_crop] [--image IMAGE]\n",
      "                             [--images IMAGES] [--video VIDEO]\n",
      "                             [--video_multiframe VIDEO_MULTIFRAME]\n",
      "                             [--score_threshold SCORE_THRESHOLD]\n",
      "                             [--dataset DATASET] [--detect] [--display_fps]\n",
      "                             [--emulate_playback]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --nms_threshold=0.5\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "def inject_eval_flags(max_images: int, score_thr=0.05, top_k=200, nms=0.5):\n",
    "    print(\"\\n=== Inject eval.py flags ===\")\n",
    "    print(f\"--max_images={max_images}, --score_threshold={score_thr}, --top_k={top_k}, --nms_threshold={nms}\")\n",
    "    eval_script.parse_args([\n",
    "        '--no_bar',\n",
    "        f'--max_images={int(max_images)}',\n",
    "        f'--score_threshold={float(score_thr)}',\n",
    "        f'--top_k={int(top_k)}',\n",
    "        f'--nms_threshold={float(nms)}'\n",
    "    ])\n",
    "\n",
    "inject_eval_flags(VALIDATION_SIZE, score_thr=EVAL_SCORE_THR, top_k=EVAL_TOP_K, nms=EVAL_NMS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a11c1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_proto_crop: True\n",
      "mask_proto_crop_with_pred_box: True\n",
      "mask_size: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"mask_proto_crop:\", getattr(cfg, \"mask_proto_crop\", None))\n",
    "print(\"mask_proto_crop_with_pred_box:\", getattr(cfg, \"mask_proto_crop_with_pred_box\", None))\n",
    "print(\"mask_size:\", getattr(cfg, \"mask_size\", None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f1eb990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODEL] load_weights: weights/cell_yolact_im700_86_1726_interrupt.pth\n",
      "\n",
      "=== CFG MASK BRANCH SETTINGS ===\n",
      "- cfg.mask_type: 1\n",
      "- cfg.mask_size: 16\n",
      "- cfg.mask_proto_net: True\n",
      "- cfg.mask_proto_crop: True\n",
      "- cfg.mask_proto_crop_with_pred_box: True\n",
      "- cfg.masks_to_train: 300\n",
      "\n",
      "=== MODEL OUTPUT INSPECTION ===\n",
      "- type: list, len=1\n",
      "  idx 0: <class 'dict'>\n",
      "\n",
      "[GT MASK] dtype: uint8 min/max: 0.0 1.0\n",
      "[WARN] Unusual gt_masks dtype. Expect bool/uint8/float.\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def load_model_and_inspect_outputs(ckpt_path=None, dev=None, probe_index=0):\n",
    "    from data import mask_type as _mask_type\n",
    "    dev = dev or device()\n",
    "    model = Yolact().to(dev)\n",
    "\n",
    "    if ckpt_path and os.path.isfile(ckpt_path):\n",
    "        print(f\"[MODEL] load_weights: {ckpt_path}\")\n",
    "        model.load_weights(ckpt_path)\n",
    "    else:\n",
    "        print(\"[MODEL] init_weights from backbone\")\n",
    "        backbone_path = cfg.backbone.path\n",
    "        if not os.path.isabs(backbone_path):\n",
    "            backbone_path = os.path.join(\"weights\", backbone_path)\n",
    "        model.init_weights(backbone_path=backbone_path)\n",
    "\n",
    "    print(\"\\n=== CFG MASK BRANCH SETTINGS ===\")\n",
    "    print(\"- cfg.mask_type:\", getattr(cfg, \"mask_type\", None))\n",
    "    print(\"- cfg.mask_size:\", getattr(cfg, \"mask_size\", None))\n",
    "    print(\"- cfg.mask_proto_net:\", getattr(cfg, \"mask_proto_net\", None) is not None)\n",
    "    print(\"- cfg.mask_proto_crop:\", getattr(cfg, \"mask_proto_crop\", None))\n",
    "    print(\"- cfg.mask_proto_crop_with_pred_box:\", getattr(cfg, \"mask_proto_crop_with_pred_box\", None))\n",
    "    print(\"- cfg.masks_to_train:\", getattr(cfg, \"masks_to_train\", None))\n",
    "\n",
    "    # 한 장으로 모델 출력 형태 조사\n",
    "    model.eval()\n",
    "    if len(dataset) == 0:\n",
    "        print(\"[WARN] dataset empty.\")\n",
    "        model.train()\n",
    "        return model\n",
    "\n",
    "    img, (tgt, gt_masks, num_crowd) = dataset[min(probe_index, len(dataset)-1)]\n",
    "    x = img.unsqueeze(0).to(dev)\n",
    "    with torch.no_grad():\n",
    "        preds = model(x)\n",
    "\n",
    "    # 출력이 dict/tuple 등 어떤 형태인지 조사\n",
    "    print(\"\\n=== MODEL OUTPUT INSPECTION ===\")\n",
    "    if isinstance(preds, dict):\n",
    "        print(\"- type: dict\")\n",
    "        print(\"- keys:\", list(preds.keys()))\n",
    "        # YOLACT 계열에서 프로토로 흔한 키 후보들\n",
    "        proto = None\n",
    "        for k in [\"proto\", \"proto_out\", \"proto_pooled\", \"mask_proto\", \"proto_masks\"]:\n",
    "            if k in preds:\n",
    "                proto = preds[k]\n",
    "                print(f\"[FOUND] proto-like key: '{k}' shape={tuple(proto.shape)}\")\n",
    "                break\n",
    "        if proto is None:\n",
    "            print(\"[INFO] proto-like key not found in dict outputs.\")\n",
    "    elif isinstance(preds, (list, tuple)):\n",
    "        print(f\"- type: {type(preds).__name__}, len={len(preds)}\")\n",
    "        # 첫 몇 개 텐서 shape 출력\n",
    "        for i, p in enumerate(preds[:6]):\n",
    "            try:\n",
    "                shape = tuple(p.shape)\n",
    "            except Exception:\n",
    "                shape = type(p)\n",
    "            print(f\"  idx {i}: {shape}\")\n",
    "    else:\n",
    "        print(\"- type:\", type(preds))\n",
    "        print(preds)\n",
    "\n",
    "    # GT 마스크 값/타입 간단 점검\n",
    "    if hasattr(gt_masks, \"dtype\"):\n",
    "        print(\"\\n[GT MASK] dtype:\", gt_masks.dtype,\n",
    "              \"min/max:\", float(gt_masks.min()), float(gt_masks.max()))\n",
    "        if gt_masks.dtype != torch.bool and gt_masks.dtype != torch.uint8 and gt_masks.dtype != torch.float32:\n",
    "            print(\"[WARN] Unusual gt_masks dtype. Expect bool/uint8/float.\")\n",
    "    model.train()\n",
    "    return model\n",
    "\n",
    "model = load_model_and_inspect_outputs(CHECKPOINT, device(), probe_index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6420f976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Postprocess Sanity Probe (k=3, score_thr=0.01) ===\n",
      "- sample #0: det=200, score[min,max]=(0.23720140755176544,0.965642511844635), classes={0: 200}\n",
      "- sample #1: det=200, score[min,max]=(0.1616656333208084,0.8309450745582581), classes={0: 200}\n",
      "- sample #2: det=200, score[min,max]=(0.20879216492176056,0.8090166449546814), classes={0: 200}\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def sanity_probe(model, ds, dev=None, k=3, score_thr=0.01):\n",
    "    dev = dev or device()\n",
    "    print(f\"\\n=== Postprocess Sanity Probe (k={k}, score_thr={score_thr}) ===\")\n",
    "    model.eval()\n",
    "    n = min(k, len(ds))\n",
    "    if n == 0:\n",
    "        print(\"⚠️ 데이터셋이 비어 있습니다.\")\n",
    "        return\n",
    "    for i in range(n):\n",
    "        img, _ = ds[i]\n",
    "        h, w = img.shape[1:]\n",
    "        x = img.unsqueeze(0).to(dev)\n",
    "        preds = model(x)\n",
    "        # NOTE: 당신 포크의 postprocess는 top_k 키워드가 없음 → 제거\n",
    "        out = postprocess(preds, w, h, score_threshold=float(score_thr))\n",
    "        if out is None:\n",
    "            print(f\"- sample #{i}: det=0 (postprocess returned None)\")\n",
    "            continue\n",
    "        classes, scores, boxes, masks = out\n",
    "        d = len(scores)\n",
    "        smin = float(scores.min()) if d > 0 else None\n",
    "        smax = float(scores.max()) if d > 0 else None\n",
    "        from collections import Counter\n",
    "        ucls = Counter([int(c) for c in classes]) if d > 0 else {}\n",
    "        print(f\"- sample #{i}: det={d}, score[min,max]=({smin},{smax}), classes={dict(ucls)}\")\n",
    "\n",
    "sanity_probe(model, dataset, device(), k=K, score_thr=PROBE_SCORE_THR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f23b2e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== One-Image Mask IoU Probe (idx=0, score_thr=0.1) ===\n",
      "Detections: 200\n",
      "[PRED MASK] sample0: shape=(1024, 1024), min/max=(0.0000,0.0000), nonzero=0\n",
      "  - pair #0: IoU=0.0000\n",
      "  - pair #1: IoU=0.0000\n",
      "  - pair #2: IoU=0.0000\n",
      "  - pair #3: IoU=0.0000\n",
      "  - pair #4: IoU=0.0000\n",
      "⚠️ 모든 샘플 IoU=0 → 마스크 정렬/크롭/스케일/포맷 문제 가능성 큼 (box는 정상일 수 있음).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def quick_mask_iou(pred_mask, gt_mask):\n",
    "    pm = pred_mask.astype(np.bool_)\n",
    "    gm = gt_mask.astype(np.bool_)\n",
    "    inter = np.logical_and(pm, gm).sum()\n",
    "    union = np.logical_or(pm, gm).sum()\n",
    "    return (inter / union) if union > 0 else 0.0\n",
    "\n",
    "@torch.no_grad()\n",
    "def probe_one_image_mask_iou(model, ds, index=0, score_thr=0.1, dev=None, max_pairs=5):\n",
    "    dev = dev or device()\n",
    "    print(f\"\\n=== One-Image Mask IoU Probe (idx={index}, score_thr={score_thr}) ===\")\n",
    "    if index >= len(ds):\n",
    "        print(\"Index out of range.\")\n",
    "        return\n",
    "    img, (tgt, gt_masks, num_crowd) = ds[index]\n",
    "    H, W = img.shape[1:]\n",
    "    x = img.unsqueeze(0).to(dev)\n",
    "    preds = model(x)\n",
    "    out = postprocess(preds, W, H, score_threshold=float(score_thr))\n",
    "    if out is None:\n",
    "        print(\"No detections.\")\n",
    "        return\n",
    "    classes, scores, boxes, masks = out  # expected masks: [N, H, W]\n",
    "    print(f\"Detections: {len(scores)}\")\n",
    "\n",
    "    # GT as numpy [K,H,W]\n",
    "    if isinstance(gt_masks, torch.Tensor):\n",
    "        gt_bin = (gt_masks.detach().cpu().float() > 0.5).numpy()\n",
    "        if gt_bin.ndim == 2:\n",
    "            gt_bin = gt_bin[None, ...]\n",
    "    else:\n",
    "        gt_bin = np.asarray(gt_masks)\n",
    "        if gt_bin.ndim == 2:\n",
    "            gt_bin = gt_bin[None, ...]\n",
    "\n",
    "    # 예측 마스크 유효성 간단 진단\n",
    "    if masks is None or len(masks) == 0:\n",
    "        print(\"⚠️ No predicted masks returned by postprocess.\")\n",
    "        return\n",
    "    # 마스크 값 범위/유효 픽셀 간단 통계\n",
    "    m0 = masks[0].detach().cpu().numpy()\n",
    "    print(f\"[PRED MASK] sample0: shape={m0.shape}, min/max=({m0.min():.4f},{m0.max():.4f}), nonzero={(m0>0).sum()}\")\n",
    "\n",
    "    m = min(len(scores), gt_bin.shape[0], max_pairs)\n",
    "    if m == 0:\n",
    "        print(\"No comparable masks (either pred or gt is empty).\")\n",
    "        return\n",
    "\n",
    "    ious = []\n",
    "    for i in range(m):\n",
    "        pm = (masks[i].detach().cpu().numpy() > 0.5).astype(np.uint8)\n",
    "        gm = gt_bin[i].astype(np.uint8) if i < gt_bin.shape[0] else gt_bin[0].astype(np.uint8)\n",
    "        iou = quick_mask_iou(pm, gm)\n",
    "        ious.append(iou)\n",
    "        print(f\"  - pair #{i}: IoU={iou:.4f}\")\n",
    "    if all(i == 0.0 for i in ious):\n",
    "        print(\"⚠️ 모든 샘플 IoU=0 → 마스크 정렬/크롭/스케일/포맷 문제 가능성 큼 (box는 정상일 수 있음).\")\n",
    "\n",
    "probe_one_image_mask_iou(model, dataset, index=0, score_thr=0.1, dev=device(), max_pairs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaea1417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Inject eval.py flags ===\n",
      "--max_images=200, --score_threshold=0.05, --top_k=200\n"
     ]
    }
   ],
   "source": [
    "def inject_eval_flags(max_images: int, score_thr=0.05, top_k=200):\n",
    "    print(\"\\n=== Inject eval.py flags ===\")\n",
    "    print(f\"--max_images={max_images}, --score_threshold={score_thr}, --top_k={top_k}\")\n",
    "    eval_script.parse_args([\n",
    "        '--no_bar',\n",
    "        f'--max_images={int(max_images)}',\n",
    "        f'--score_threshold={float(score_thr)}',\n",
    "        f'--top_k={int(top_k)}'\n",
    "    ])\n",
    "\n",
    "inject_eval_flags(VALIDATION_SIZE, score_thr=EVAL_SCORE_THR, top_k=EVAL_TOP_K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9554ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Runtime Mask-Crop Toggle (for quick test) ===\n",
      "BEFORE  - mask_proto_crop: True  mask_proto_crop_with_pred_box: True\n",
      "APPLIED - mask_proto_crop: True  mask_proto_crop_with_pred_box: True\n",
      "\n",
      "=== Postprocess Sanity Probe (k=3, score_thr=0.01) ===\n",
      "- sample #0: det=200, score[min,max]=(0.23720140755176544,0.965642511844635), classes={0: 200}\n",
      "- sample #1: det=200, score[min,max]=(0.1616656333208084,0.8309450745582581), classes={0: 200}\n",
      "- sample #2: det=200, score[min,max]=(0.20879216492176056,0.8090166449546814), classes={0: 200}\n",
      "\n",
      "=== One-Image Mask IoU Probe (idx=0, score_thr=0.1) ===\n",
      "Detections: 200\n",
      "[PRED MASK] sample0: shape=(1024, 1024), min/max=(0.0000,0.0000), nonzero=0\n",
      "  - pair #0: IoU=0.0000\n",
      "  - pair #1: IoU=0.0000\n",
      "  - pair #2: IoU=0.0000\n",
      "  - pair #3: IoU=0.0000\n",
      "  - pair #4: IoU=0.0000\n",
      "⚠️ 모든 샘플 IoU=0 → 마스크 정렬/크롭/스케일/포맷 문제 가능성 큼 (box는 정상일 수 있음).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Runtime Mask-Crop Toggle (for quick test) ===\")\n",
    "before_crop  = getattr(cfg, \"mask_proto_crop\", None)\n",
    "before_cropb = getattr(cfg, \"mask_proto_crop_with_pred_box\", None)\n",
    "print(\"BEFORE  - mask_proto_crop:\", before_crop, \" mask_proto_crop_with_pred_box:\", before_cropb)\n",
    "\n",
    "cfg.mask_proto_crop = True\n",
    "cfg.mask_proto_crop_with_pred_box = True\n",
    "\n",
    "print(\"APPLIED - mask_proto_crop:\", cfg.mask_proto_crop, \" mask_proto_crop_with_pred_box:\", cfg.mask_proto_crop_with_pred_box)\n",
    "\n",
    "# 모델은 cfg를 참조해 postprocess하므로, 같은 모델로 다시 probe\n",
    "sanity_probe(model, dataset, device(), k=K, score_thr=PROBE_SCORE_THR)\n",
    "probe_one_image_mask_iou(model, dataset, index=0, score_thr=0.1, dev=device(), max_pairs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba75a306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RAW OUTPUT KEYS / TYPES ===\n",
      "type: list\n",
      "\n",
      "=== STATS ===\n",
      "PROTO: None\n",
      "COEFF: None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "@torch.no_grad()\n",
    "def inspect_proto_and_coeffs(model, ds, idx=0, dev=None):\n",
    "    dev = dev or device()\n",
    "    model.eval()\n",
    "\n",
    "    img, (tgt, gt_masks, num_crowd) = ds[idx]\n",
    "    H, W = img.shape[1:]\n",
    "    x = img.unsqueeze(0).to(dev)\n",
    "    preds = model(x)\n",
    "\n",
    "    print(\"\\n=== RAW OUTPUT KEYS / TYPES ===\")\n",
    "    proto = None\n",
    "    coeff = None\n",
    "    out_type = type(preds).__name__\n",
    "    print(\"type:\", out_type)\n",
    "\n",
    "    # 1) dict인 경우 키 탐색\n",
    "    if isinstance(preds, dict):\n",
    "        keys = list(preds.keys())\n",
    "        print(\"keys:\", keys)\n",
    "\n",
    "        # proto 후보 키들\n",
    "        for k in [\"proto\", \"proto_out\", \"mask_proto\", \"proto_pooled\", \"proto_masks\"]:\n",
    "            if k in preds and isinstance(preds[k], torch.Tensor):\n",
    "                proto = preds[k]\n",
    "                print(f\"[FOUND] proto='{k}' shape={tuple(proto.shape)}\")\n",
    "                break\n",
    "\n",
    "        # coeff 후보 키들\n",
    "        for k in [\"mask\", \"mask_coeff\", \"coeff\", \"coeffs\", \"proto_coeff\", \"mask_coefficients\"]:\n",
    "            if k in preds and isinstance(preds[k], torch.Tensor):\n",
    "                coeff = preds[k]\n",
    "                print(f\"[FOUND] coeff='{k}' shape={tuple(coeff.shape)}\")\n",
    "                break\n",
    "\n",
    "    # 2) list/tuple인 경우 모양으로 추정\n",
    "    elif isinstance(preds, (list, tuple)):\n",
    "        for i, p in enumerate(preds):\n",
    "            if isinstance(p, torch.Tensor):\n",
    "                shape = tuple(p.shape)\n",
    "                print(f\"idx {i}: {shape}\")\n",
    "                # 대략적인 휴리스틱: proto는 [B, H', W', K], coeff는 [N, K]\n",
    "                if proto is None and len(shape) == 4 and shape[0] == 1 and min(shape[1],shape[2])<=128 and shape[3]>=8:\n",
    "                    proto = p\n",
    "                    print(f\"[GUESS] proto at idx {i}\")\n",
    "                if coeff is None and len(shape) == 2 and shape[1] >= 8 and shape[0] > 0:\n",
    "                    coeff = p\n",
    "                    print(f\"[GUESS] coeff at idx {i}\")\n",
    "\n",
    "    # 통계 출력\n",
    "    def stat(name, t):\n",
    "        if t is None:\n",
    "            print(f\"{name}: None\")\n",
    "            return\n",
    "        a = t.detach().float().cpu()\n",
    "        print(f\"{name}: shape={tuple(a.shape)}, min={a.min().item():.4g}, max={a.max().item():.4g}, mean={a.mean().item():.4g}, norm={a.norm().item():.4g}\")\n",
    "\n",
    "    print(\"\\n=== STATS ===\")\n",
    "    stat(\"PROTO\", proto)\n",
    "    stat(\"COEFF\", coeff)\n",
    "\n",
    "    # 반환해서 다음 셀에서 바로 재사용 가능\n",
    "    return proto, coeff, preds\n",
    "\n",
    "proto, coeff, raw_preds = inspect_proto_and_coeffs(model, dataset, idx=0, dev=device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51934b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proto/coeff to compose.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def try_direct_lincomb(proto, coeff, top_n=5, upsample_to=None):\n",
    "    \"\"\"\n",
    "    proto: [1, H', W', K] 또는 [H', W', K] 가능\n",
    "    coeff: [N, K]\n",
    "    \"\"\"\n",
    "    if proto is None or coeff is None:\n",
    "        print(\"No proto/coeff to compose.\")\n",
    "        return\n",
    "\n",
    "    p = proto\n",
    "    if p.dim()==4 and p.shape[0]==1:\n",
    "        p = p[0]  # [H', W', K]\n",
    "    if p.dim()!=3:\n",
    "        print(\"Unexpected proto shape:\", tuple(proto.shape))\n",
    "        return\n",
    "\n",
    "    H_, W_, K = p.shape\n",
    "    N, K2 = coeff.shape\n",
    "    if K != K2:\n",
    "        print(f\"Channel mismatch: proto.K={K}, coeff.K={K2}\")\n",
    "        return\n",
    "\n",
    "    # 상위 N개 (최대 top_n)만 합성\n",
    "    n = min(N, top_n)\n",
    "    masks = []\n",
    "    for i in range(n):\n",
    "        c = coeff[i].detach().cpu().float()           # [K]\n",
    "        m_small = (p.detach().cpu().float() @ c).numpy()   # [H', W']\n",
    "        masks.append(m_small)\n",
    "\n",
    "    masks = np.stack(masks, axis=0)  # [n, H', W']\n",
    "    print(f\"[LINCOMB] small masks: shape={masks.shape}, min={masks.min():.4f}, max={masks.max():.4f}, mean={masks.mean():.4f}\")\n",
    "\n",
    "    # 업샘플 테스트 (선택)\n",
    "    if upsample_to is not None:\n",
    "        H, W = upsample_to\n",
    "        t = torch.from_numpy(masks).unsqueeze(1)      # [n,1,H',W']\n",
    "        t_up = F.interpolate(t, size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "        mu = t_up.squeeze(1).numpy()\n",
    "        print(f\"[LINCOMB] upsampled: shape={mu.shape}, min={mu.min():.4f}, max={mu.max():.4f}, mean={mu.mean():.4f}\")\n",
    "        nz = (mu > 0).sum()\n",
    "        print(f\"[LINCOMB] upsampled nonzero: {nz}\")\n",
    "    return masks\n",
    "\n",
    "# proto/coeff가 있을 때만 실행\n",
    "_ = try_direct_lincomb(proto, coeff, top_n=5, upsample_to=(dataset[0][0].shape[1], dataset[0][0].shape[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c74985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     31\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoss probe failed:\u001b[39m\u001b[33m\"\u001b[39m, e)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mquick_mask_loss_probe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_n\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.yolaVenv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mquick_mask_loss_probe\u001b[39m\u001b[34m(sample_n)\u001b[39m\n\u001b[32m     10\u001b[39m batch = [train_set[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(sample_n, \u001b[38;5;28mlen\u001b[39m(train_set)))]\n\u001b[32m     11\u001b[39m images = torch.stack([b[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], \u001b[32m0\u001b[39m).to(device())  \u001b[38;5;66;03m# [B,3,H,W]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m targets = [\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m(device()) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch]              \u001b[38;5;66;03m# 포크에 따라 조정\u001b[39;00m\n\u001b[32m     13\u001b[39m gt_masks = [b[\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m].to(device()) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[32m     14\u001b[39m num_crowds = [b[\u001b[32m1\u001b[39m][\u001b[32m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch]                        \u001b[38;5;66;03m# 그대로 전달만\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "from layers.modules import MultiBoxLoss\n",
    "from utils.augmentations import SSDAugmentation\n",
    "\n",
    "@torch.no_grad()\n",
    "def quick_mask_loss_probe(sample_n=4):\n",
    "    train_set = COCODetection(cfg.dataset.train_images, cfg.dataset.train_info, transform=SSDAugmentation(MEANS))\n",
    "    if len(train_set) == 0:\n",
    "        print(\"Train set empty.\")\n",
    "        return\n",
    "    batch = [train_set[i] for i in range(min(sample_n, len(train_set)))]\n",
    "    images = torch.stack([b[0] for b in batch], 0).to(device())  # [B,3,H,W]\n",
    "    targets = [b[1][0].to(device()) for b in batch]              # 포크에 따라 조정\n",
    "    gt_masks = [b[1][1].to(device()) for b in batch]\n",
    "    num_crowds = [b[1][2] for b in batch]                        # 그대로 전달만\n",
    "\n",
    "    model.eval()\n",
    "    preds = model(images)\n",
    "\n",
    "    crit = MultiBoxLoss(num_classes=cfg.num_classes,\n",
    "                        pos_threshold=cfg.positive_iou_threshold,\n",
    "                        neg_threshold=cfg.negative_iou_threshold,\n",
    "                        negpos_ratio=cfg.ohem_negpos_ratio)\n",
    "    # 포크별로 wrapper 필요할 수 있음. 기본 시도:\n",
    "    try:\n",
    "        losses = crit(model, preds, targets, gt_masks, num_crowds)\n",
    "        # 보통 키 'M' (mask), 'B','C','P' 등 존재\n",
    "        print(\"Loss keys:\", list(losses.keys()))\n",
    "        for k,v in losses.items():\n",
    "            print(f\" {k}: {float(v.mean()):.6f}\")\n",
    "    except Exception as e:\n",
    "        print(\"Loss probe failed:\", e)\n",
    "\n",
    "quick_mask_loss_probe(sample_n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6a5b0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LIST OUTPUT INSPECTION ===\n",
      "type: list\n",
      "idx 0: type=<class 'dict'>\n",
      "\n",
      "=== ROLE GUESSES ===\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def inspect_list_outputs(model, ds, idx=0, dev=None):\n",
    "    dev = dev or device()\n",
    "    model.eval()\n",
    "    img, _ = ds[idx]\n",
    "    x = img.unsqueeze(0).to(dev)\n",
    "    outs = model(x)\n",
    "\n",
    "    print(\"\\n=== LIST OUTPUT INSPECTION ===\")\n",
    "    print(\"type:\", type(outs).__name__)\n",
    "    if not isinstance(outs, (list, tuple)):\n",
    "        print(\"Not a list/tuple. Got:\", type(outs))\n",
    "        return outs, {}\n",
    "\n",
    "    roles = {}\n",
    "    for i, t in enumerate(outs):\n",
    "        if isinstance(t, torch.Tensor):\n",
    "            shp = tuple(t.shape)\n",
    "            print(f\"idx {i}: Tensor shape={shp}\")\n",
    "            # 휴리스틱으로 역할 추정\n",
    "            # - loc: [B, N, 4]\n",
    "            # - conf: [B, N, C]\n",
    "            # - coeff(mask): [B, N, K]  (K >= 8)\n",
    "            # - priors: [N, 4] or [1, N, 4]\n",
    "            # - proto: [B, H', W', K] (K >= 8, H' W' 비교적 작음)\n",
    "            B = shp[0] if len(shp) >= 1 else None\n",
    "            if len(shp) == 3 and shp[-1] == 4 and B is not None:\n",
    "                roles.setdefault('loc_idx', []).append(i)\n",
    "            elif len(shp) == 3 and B is not None and shp[-1] >= 2:\n",
    "                # conf or coeff\n",
    "                roles.setdefault('conf_or_coeff_idx', []).append((i, shp[-1]))\n",
    "            elif len(shp) == 2 and shp[-1] == 4:\n",
    "                roles.setdefault('priors_idx', []).append(i)\n",
    "            elif len(shp) == 4 and shp[0] == 1 and shp[-1] >= 8:\n",
    "                roles.setdefault('proto_idx', []).append(i)\n",
    "        else:\n",
    "            print(f\"idx {i}: type={type(t)}\")\n",
    "\n",
    "    print(\"\\n=== ROLE GUESSES ===\")\n",
    "    for k,v in roles.items():\n",
    "        print(k, \":\", v)\n",
    "    return outs, roles\n",
    "\n",
    "raw_list, role_guess = inspect_list_outputs(model, dataset, idx=0, dev=device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f7bf8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL MASK MODULES PRESENCE ===\n",
      "hasattr(model, 'proto_net'): True\n",
      "hasattr(model, 'mask_linear'): False\n",
      "hasattr(model, 'mask_upconv'): False\n",
      "hasattr(model, 'maskiou_net'): False\n",
      "hasattr(model, 'prediction_layers'): True\n",
      "\n",
      "=== CFG MASK SETTINGS ===\n",
      "mask_type: 1\n",
      "mask_size: 16\n",
      "mask_proto_net exists: True\n",
      "mask_proto_src: 0\n",
      "mask_proto_crop: True\n",
      "mask_proto_crop_with_pred_box: True\n",
      "use_maskiou: False rescore_mask: True\n"
     ]
    }
   ],
   "source": [
    "def probe_model_mask_modules(m):\n",
    "    print(\"\\n=== MODEL MASK MODULES PRESENCE ===\")\n",
    "    for name in [\"proto_net\", \"mask_linear\", \"mask_upconv\", \"maskiou_net\", \"prediction_layers\"]:\n",
    "        print(f\"hasattr(model, '{name}'):\", hasattr(m, name))\n",
    "    # cfg에 설정된 mask_type/옵션도 다시 확인\n",
    "    print(\"\\n=== CFG MASK SETTINGS ===\")\n",
    "    print(\"mask_type:\", getattr(cfg, \"mask_type\", None))\n",
    "    print(\"mask_size:\", getattr(cfg, \"mask_size\", None))\n",
    "    print(\"mask_proto_net exists:\", getattr(cfg, \"mask_proto_net\", None) is not None)\n",
    "    print(\"mask_proto_src:\", getattr(cfg, \"mask_proto_src\", None))\n",
    "    print(\"mask_proto_crop:\", getattr(cfg, \"mask_proto_crop\", None))\n",
    "    print(\"mask_proto_crop_with_pred_box:\", getattr(cfg, \"mask_proto_crop_with_pred_box\", None))\n",
    "    print(\"use_maskiou:\", getattr(cfg, \"use_maskiou\", None), \"rescore_mask:\", getattr(cfg, \"rescore_mask\", None))\n",
    "\n",
    "probe_model_mask_modules(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bb286e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proto/coeff found -> cannot compose lincomb.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def try_lincomb_from_list_outputs(outs, roles, H, W):\n",
    "    \"\"\"\n",
    "    outs: list/tuple of tensors from model(x)\n",
    "    roles: from D1\n",
    "    H, W: upsample target size\n",
    "    \"\"\"\n",
    "    # proto 후보\n",
    "    proto = None\n",
    "    if 'proto_idx' in roles and len(roles['proto_idx']) > 0:\n",
    "        pi = roles['proto_idx'][0]\n",
    "        proto = outs[pi]\n",
    "        if proto.dim()==4 and proto.shape[0]==1:\n",
    "            proto = proto[0]  # [H',W',K]\n",
    "\n",
    "    # conf/coeff 후보들\n",
    "    coeff = None\n",
    "    num_classes = getattr(cfg, \"num_classes\", None)\n",
    "    if 'conf_or_coeff_idx' in roles:\n",
    "        # conf 채널 수(=num_classes)와 일치하면 conf, 그 외 큰 채널(K) 쪽을 coeff로 가정\n",
    "        for i, ch in roles['conf_or_coeff_idx']:\n",
    "            if num_classes is not None and ch == num_classes:\n",
    "                pass  # conf\n",
    "            elif ch >= 8:\n",
    "                coeff = outs[i]\n",
    "                break\n",
    "\n",
    "    if proto is None or coeff is None:\n",
    "        print(\"No proto/coeff found -> cannot compose lincomb.\")\n",
    "        return\n",
    "\n",
    "    # [B,N,K] -> N,K\n",
    "    if coeff.dim()==3:\n",
    "        coeff = coeff[0]\n",
    "\n",
    "    print(\"\\n=== LINCOMB FROM LIST OUTS ===\")\n",
    "    print(\"proto:\", tuple(proto.shape), \"coeff:\", tuple(coeff.shape))\n",
    "    P_H, P_W, K = proto.shape\n",
    "    N, K2 = coeff.shape\n",
    "    if K != K2:\n",
    "        print(f\"Channel mismatch: proto.K={K}, coeff.K={K2}\")\n",
    "        return\n",
    "\n",
    "    # 상위 5개만 테스트\n",
    "    n = min(N, 5)\n",
    "    p_np = proto.detach().cpu().float().numpy()   # [H',W',K]\n",
    "    masks_small = []\n",
    "    for i in range(n):\n",
    "        c = coeff[i].detach().cpu().float().numpy()  # [K]\n",
    "        m = p_np @ c                                  # [H',W']\n",
    "        masks_small.append(m)\n",
    "    masks_small = np.stack(masks_small, 0)            # [n,H',W']\n",
    "    print(f\"[small] shape={masks_small.shape}, min={masks_small.min():.4f}, max={masks_small.max():.4f}, mean={masks_small.mean():.4f}\")\n",
    "\n",
    "    # 업샘플\n",
    "    t = torch.from_numpy(masks_small).unsqueeze(1)\n",
    "    up = F.interpolate(t, size=(H, W), mode=\"bilinear\", align_corners=False).squeeze(1).numpy()\n",
    "    nz = (up > 0).sum()\n",
    "    print(f\"[upsampled] shape={up.shape}, min={up.min():.4f}, max={up.max():.4f}, mean={up.mean():.4f}, nonzero={nz}\")\n",
    "\n",
    "# 실행\n",
    "img0, _ = dataset[0]\n",
    "H0, W0 = img0.shape[1:]\n",
    "try_lincomb_from_list_outputs(raw_list, role_guess, H0, W0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16e85c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "Could not import MultiBoxLoss compatible path: 'numpy.ndarray' object has no attribute 'to'\n"
     ]
    }
   ],
   "source": [
    "# 최대한 호환을 맞추는 손쉬운 버전 (없는 경우 자동 스킵)\n",
    "try:\n",
    "    from layers.modules import MultiBoxLoss\n",
    "    from utils.augmentations import SSDAugmentation\n",
    "    # 어떤 포크는 ScatterWrapper가 여기/다른 모듈에 존재\n",
    "    try:\n",
    "        from layers.output_utils import ScatterWrapper\n",
    "    except Exception:\n",
    "        ScatterWrapper = None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def quick_mask_loss_probe_safe(sample_n=2):\n",
    "        train_set = COCODetection(cfg.dataset.train_images, cfg.dataset.train_info, transform=SSDAugmentation(MEANS))\n",
    "        if len(train_set) == 0:\n",
    "            print(\"Train set empty.\")\n",
    "            return\n",
    "        batch = [train_set[i] for i in range(min(sample_n, len(train_set)))]\n",
    "        images = torch.stack([b[0] for b in batch], 0).to(device())\n",
    "        targets = [b[1][0].to(device()) for b in batch]\n",
    "        gt_masks = [b[1][1].to(device()) for b in batch]\n",
    "        num_crowds = [b[1][2] for b in batch]\n",
    "\n",
    "        model.eval()\n",
    "        preds = model(images)\n",
    "\n",
    "        crit = MultiBoxLoss(num_classes=cfg.num_classes,\n",
    "                            pos_threshold=cfg.positive_iou_threshold,\n",
    "                            neg_threshold=cfg.negative_iou_threshold,\n",
    "                            negpos_ratio=cfg.ohem_negpos_ratio)\n",
    "\n",
    "        try:\n",
    "            if ScatterWrapper is not None and isinstance(preds, (list, tuple)):\n",
    "                # 일부 포크는 이렇게 호출: criterion(preds, wrapper, mask)\n",
    "                wrapper = ScatterWrapper(targets, gt_masks, num_crowds)\n",
    "                losses = crit(preds, wrapper, wrapper.make_mask())\n",
    "            else:\n",
    "                # train.py의 NetLoss처럼 호출 (포크에 따라 다름)\n",
    "                losses = crit(model, preds, targets, gt_masks, num_crowds)\n",
    "\n",
    "            print(\"Loss keys:\", list(losses.keys()))\n",
    "            for k,v in losses.items():\n",
    "                try:\n",
    "                    vv = float(v.mean())\n",
    "                except Exception:\n",
    "                    vv = float(v)\n",
    "                print(f\" {k}: {vv:.6f}\")\n",
    "        except Exception as e:\n",
    "            print(\"Loss probe failed:\", e)\n",
    "\n",
    "    quick_mask_loss_probe_safe(sample_n=2)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Could not import MultiBoxLoss compatible path:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f50794ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INNER DICT INSPECTION ===\n",
      "dict keys: ['detection', 'net']\n",
      "  - detection    type=<class 'dict'>\n",
      "  - net          type=<class 'yolact.Yolact'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def inspect_inner_dict(model, ds, idx=0, dev=None):\n",
    "    dev = dev or device()\n",
    "    model.eval()\n",
    "    img, _ = ds[idx]\n",
    "    x = img.unsqueeze(0).to(dev)\n",
    "    outs = model(x)\n",
    "\n",
    "    print(\"\\n=== INNER DICT INSPECTION ===\")\n",
    "    if not (isinstance(outs, (list, tuple)) and len(outs) > 0 and isinstance(outs[0], dict)):\n",
    "        print(\"Unexpected structure. Got:\", type(outs))\n",
    "        return None\n",
    "\n",
    "    d = outs[0]\n",
    "    print(\"dict keys:\", list(d.keys()))\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            t = v.detach().float().cpu()\n",
    "            shp = tuple(t.shape)\n",
    "            try:\n",
    "                vmin, vmax, vmean, vnorm = t.min().item(), t.max().item(), t.mean().item(), t.norm().item()\n",
    "                print(f\"  - {k:12s} shape={shp}  min={vmin:.4g} max={vmax:.4g} mean={vmean:.4g} norm={vnorm:.4g}\")\n",
    "            except Exception:\n",
    "                print(f\"  - {k:12s} shape={shp}\")\n",
    "        else:\n",
    "            print(f\"  - {k:12s} type={type(v)}\")\n",
    "    return d\n",
    "\n",
    "inner = inspect_inner_dict(model, dataset, idx=0, dev=device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96cad4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Missing keys for postprocess: ['loc', 'conf', 'coeff', 'priors', 'proto']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     47\u001b[39m         m0 = masks[\u001b[32m0\u001b[39m].detach().cpu().numpy()\n\u001b[32m     48\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[PRED MASK] sample0: shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm0.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, min/max=(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm0.min()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm0.max()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m), nonzero=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(m0>\u001b[32m0\u001b[39m).sum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[43mtry_postprocess_from_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_thr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.yolaVenv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mtry_postprocess_from_inner\u001b[39m\u001b[34m(model, ds, idx, score_thr, dev)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# postprocess는 대개 (preds_tuple, W, H, ...) 형태를 받습니다.\u001b[39;00m\n\u001b[32m     37\u001b[39m preds_tuple = (loc, conf, coeff, priors, proto)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m out = \u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds_tuple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscore_thr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpostprocess returned None.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/yolact/layers/output_utils.py:36\u001b[39m, in \u001b[36mpostprocess\u001b[39m\u001b[34m(det_output, w, h, batch_idx, interpolation_mode, visualize_lincomb, crop_masks, score_threshold)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03mPostprocesses the output of Yolact on testing mode into a format that makes sense,\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03maccounting for all the possible configuration settings.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m \u001b[33;03m    - masks   [num_det, h, w]: Full image masks for each detection.\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     35\u001b[39m dets = det_output[batch_idx]\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m net = \u001b[43mdets\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     37\u001b[39m dets = dets[\u001b[33m'\u001b[39m\u001b[33mdetection\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from layers.output_utils import postprocess\n",
    "\n",
    "def build_postprocess_tuple_from_inner(d):\n",
    "    \"\"\"\n",
    "    당신 포크의 키 이름을 추정해서 (loc, conf, mask_coeff, priors, proto) 튜플을 만들어줍니다.\n",
    "    없는 건 None 반환.\n",
    "    \"\"\"\n",
    "    # 흔한 키 이름 후보\n",
    "    loc    = d.get('loc')    or d.get('boxes') or d.get('bbox')\n",
    "    conf   = d.get('conf')   or d.get('scores') or d.get('cls')\n",
    "    coeff  = d.get('mask')   or d.get('mask_coeff') or d.get('coeff') or d.get('mask_coefficients')\n",
    "    priors = d.get('priors') or d.get('anchors') or d.get('default_boxes') or d.get('dboxes')\n",
    "    proto  = d.get('proto')  or d.get('proto_out') or d.get('mask_proto') or d.get('proto_masks') or d.get('proto_pooled')\n",
    "\n",
    "    missing = [name for name, obj in [('loc',loc),('conf',conf),('coeff',coeff),('priors',priors),('proto',proto)] if obj is None]\n",
    "    if missing:\n",
    "        print(\"⚠️ Missing keys for postprocess:\", missing)\n",
    "    return (loc, conf, coeff, priors, proto)\n",
    "\n",
    "@torch.no_grad()\n",
    "def try_postprocess_from_inner(model, ds, idx=0, score_thr=0.05, dev=None):\n",
    "    dev = dev or device()\n",
    "    model.eval()\n",
    "    img, _ = ds[idx]\n",
    "    H, W = img.shape[1:]\n",
    "    x = img.unsqueeze(0).to(dev)\n",
    "    outs = model(x)\n",
    "    if not (isinstance(outs, (list, tuple)) and len(outs) > 0 and isinstance(outs[0], dict)):\n",
    "        print(\"Structure not supported for this probe.\")\n",
    "        return\n",
    "    d = outs[0]\n",
    "    loc, conf, coeff, priors, proto = build_postprocess_tuple_from_inner(d)\n",
    "\n",
    "    # postprocess는 대개 (preds_tuple, W, H, ...) 형태를 받습니다.\n",
    "    preds_tuple = (loc, conf, coeff, priors, proto)\n",
    "    out = postprocess(preds_tuple, W, H, score_threshold=float(score_thr))\n",
    "    if out is None:\n",
    "        print(\"postprocess returned None.\")\n",
    "        return\n",
    "    classes, scores, boxes, masks = out\n",
    "    print(f\"Detections: {len(scores)}\")\n",
    "    if masks is None or len(masks) == 0:\n",
    "        print(\"⚠️ No predicted masks returned.\")\n",
    "    else:\n",
    "        m0 = masks[0].detach().cpu().numpy()\n",
    "        print(f\"[PRED MASK] sample0: shape={m0.shape}, min/max=({m0.min():.4f},{m0.max():.4f}), nonzero={(m0>0).sum()}\")\n",
    "\n",
    "try_postprocess_from_inner(model, dataset, idx=0, score_thr=0.05, dev=device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fac6b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DETECTION DICT (DEEP INSPECTION) ===\n",
      "detection.keys: ['box', 'mask', 'class', 'score', 'proto']\n",
      "  - box              shape=(200, 4)  min=-0.00352 max=1 mean=0.5048 norm=15.73\n",
      "  - mask             shape=(200, 32)  min=-0.9992 max=0.9968 mean=-0.1118 norm=54.71\n",
      "  - class            shape=(200,)  min=0 max=0 mean=0 norm=0\n",
      "  - score            shape=(200,)  min=0.2372 max=0.9656 mean=0.3782 norm=5.916\n",
      "  - proto            shape=(256, 256, 32)  min=0 max=10.11 mean=0.5887 norm=1845\n",
      "\n",
      "=== SUMMARY (LIKELY) ===\n",
      "proto   : shape=(256, 256, 32)  min=0 max=10.11 mean=0.5887\n",
      "coeff   : shape=(200, 32)  min=-0.9992 max=0.9968 mean=-0.1118\n",
      "boxes   : shape=(200, 4)  min=-0.00352 max=1 mean=0.5048\n",
      "scores  : shape=(200,)  min=0.2372 max=0.9656 mean=0.3782\n",
      "classes : shape=(200,)  min=0 max=0 mean=0\n",
      "priors  : None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def inspect_detection_deep(model, ds, idx=0, dev=None, max_items=50):\n",
    "    dev = dev or device()\n",
    "    model.eval()\n",
    "    img, _ = ds[idx]\n",
    "    x = img.unsqueeze(0).to(dev)\n",
    "    outs = model(x)\n",
    "\n",
    "    print(\"\\n=== DETECTION DICT (DEEP INSPECTION) ===\")\n",
    "    if not (isinstance(outs, (list, tuple)) and len(outs) > 0 and isinstance(outs[0], dict)):\n",
    "        print(\"Unexpected structure:\", type(outs))\n",
    "        return None\n",
    "\n",
    "    inner = outs[0]\n",
    "    det = inner.get('detection', None)\n",
    "    if not isinstance(det, dict):\n",
    "        print(\"No 'detection' dict. Got:\", type(det))\n",
    "        return None\n",
    "\n",
    "    keys = list(det.keys())\n",
    "    print(\"detection.keys:\", keys[:max_items])\n",
    "\n",
    "    # 흔히 등장하는 키 후보들을 먼저 보자\n",
    "    likely_proto_keys = ['proto', 'proto_out', 'mask_proto', 'proto_masks', 'proto_pooled']\n",
    "    likely_coeff_keys = ['mask', 'mask_coeff', 'coeff', 'mask_coefficients', 'proto_coeff']\n",
    "\n",
    "    found = {'proto': None, 'coeff': None, 'boxes': None, 'scores': None, 'classes': None, 'priors': None}\n",
    "    for k in keys:\n",
    "        v = det[k]\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            t = v.detach().float().cpu()\n",
    "            shp = tuple(t.shape)\n",
    "            vmin, vmax, vmean, vnorm = t.min().item(), t.max().item(), t.mean().item(), t.norm().item()\n",
    "            print(f\"  - {k:16s} shape={shp}  min={vmin:.4g} max={vmax:.4g} mean={vmean:.4g} norm={vnorm:.4g}\")\n",
    "\n",
    "            # 역할 추정\n",
    "            if k in likely_proto_keys and found['proto'] is None:\n",
    "                found['proto'] = t\n",
    "            if k in likely_coeff_keys and found['coeff'] is None:\n",
    "                found['coeff'] = t\n",
    "            if 'box' in k and found['boxes'] is None:\n",
    "                found['boxes'] = t\n",
    "            if 'score' in k and found['scores'] is None:\n",
    "                found['scores'] = t\n",
    "            if 'class' in k and found['classes'] is None:\n",
    "                found['classes'] = t\n",
    "            if 'prior' in k or 'anchor' in k or 'dflt' in k:\n",
    "                found['priors'] = t\n",
    "        else:\n",
    "            print(f\"  - {k:16s} type={type(v)}\")\n",
    "\n",
    "    # 요약\n",
    "    print(\"\\n=== SUMMARY (LIKELY) ===\")\n",
    "    for name, val in found.items():\n",
    "        if isinstance(val, torch.Tensor):\n",
    "            print(f\"{name:8s}: shape={tuple(val.shape)}  min={float(val.min()):.4g} max={float(val.max()):.4g} mean={float(val.mean()):.4g}\")\n",
    "        else:\n",
    "            print(f\"{name:8s}: {val}\")\n",
    "\n",
    "    return det, found\n",
    "\n",
    "det_dict, found = inspect_detection_deep(model, dataset, idx=0, dev=device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f4c26b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[small] shape=(5, 256, 256), min=-36.7743, max=-1.7035, mean=-14.6955\n",
      "[upsampled] shape=(5, 1024, 1024), min=-36.7641, max=-1.7035, mean=-14.6955, nonzero=0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def try_lincomb_from_detection(found, H, W, top_n=5):\n",
    "    proto = found.get('proto', None)\n",
    "    coeff = found.get('coeff', None)\n",
    "    if proto is None or coeff is None:\n",
    "        print(\"No proto/coeff in detection dict.\")\n",
    "        return\n",
    "\n",
    "    p = proto  # CPU float tensor\n",
    "    c = coeff  # CPU float tensor\n",
    "\n",
    "    # proto shape 정규화: [H', W', K]\n",
    "    if p.dim() == 4 and p.shape[0] == 1:\n",
    "        p = p[0]\n",
    "    if p.dim() != 3:\n",
    "        print(\"Unexpected proto shape:\", tuple(p.shape))\n",
    "        return\n",
    "\n",
    "    H_, W_, K = p.shape\n",
    "    if c.dim() == 3:  # [B, N, K]\n",
    "        c = c[0]\n",
    "    if c.dim() != 2:\n",
    "        print(\"Unexpected coeff shape:\", tuple(c.shape))\n",
    "        return\n",
    "    N, K2 = c.shape\n",
    "    if K != K2:\n",
    "        print(f\"Channel mismatch: proto.K={K}, coeff.K={K2}\")\n",
    "        return\n",
    "\n",
    "    n = min(N, top_n)\n",
    "    p_np = p.numpy()\n",
    "    masks_small = []\n",
    "    for i in range(n):\n",
    "        m = p_np @ c[i].numpy()  # [H', W']\n",
    "        masks_small.append(m)\n",
    "    masks_small = np.stack(masks_small, 0)  # [n,H',W']\n",
    "    print(f\"[small] shape={masks_small.shape}, min={masks_small.min():.4f}, max={masks_small.max():.4f}, mean={masks_small.mean():.4f}\")\n",
    "\n",
    "    # 업샘플\n",
    "    t = torch.from_numpy(masks_small).unsqueeze(1)         # [n,1,H',W']\n",
    "    up = F.interpolate(t, size=(H, W), mode=\"bilinear\", align_corners=False).squeeze(1).numpy()\n",
    "    nz = (up > 0).sum()\n",
    "    print(f\"[upsampled] shape={up.shape}, min={up.min():.4f}, max={up.max():.4f}, mean={up.mean():.4f}, nonzero={nz}\")\n",
    "\n",
    "# 실행\n",
    "img0, _ = dataset[0]\n",
    "H0, W0 = img0.shape[1:]\n",
    "try_lincomb_from_detection(found, H0, W0, top_n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84879522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] masks_bin: shape=(5, 1024, 1024), nonzero_total=0\n",
      "  - pair#0 IoU=0.0000 (score=0.966)\n",
      "  - pair#1 IoU=0.0000 (score=0.943)\n",
      "  - pair#2 IoU=0.0000 (score=0.938)\n",
      "  - pair#3 IoU=0.0000 (score=0.932)\n",
      "  - pair#4 IoU=0.0000 (score=0.922)\n",
      "[DEBUG] masks_bin: shape=(5, 1024, 1024), nonzero_total=0\n",
      "  - pair#0 IoU=0.0000 (score=0.966)\n",
      "  - pair#1 IoU=0.0000 (score=0.943)\n",
      "  - pair#2 IoU=0.0000 (score=0.938)\n",
      "  - pair#3 IoU=0.0000 (score=0.932)\n",
      "  - pair#4 IoU=0.0000 (score=0.922)\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.no_grad()\n",
    "def compose_masks_with_sigmoid_and_crop(model, ds, idx=0, score_thr=0.05, bin_thr=0.5, dev=None, top_k=5):\n",
    "    dev = dev or (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "    model.eval()\n",
    "    img, (tgt, gt_masks, num_crowd) = ds[idx]\n",
    "    H, W = img.shape[1:]\n",
    "    x = img.unsqueeze(0).to(dev)\n",
    "\n",
    "    # 모델 출력\n",
    "    outs = model(x)\n",
    "    det = outs[0]['detection']\n",
    "    boxes = det['box'].detach().cpu()           # [N,4] in xyxy (0~1) or abs? *당신 포크 기준 지금 0~1*\n",
    "    scores = det['score'].detach().cpu()        # [N]\n",
    "    classes = det['class'].detach().cpu()       # [N]\n",
    "    coeff  = det['mask'].detach().cpu().float() # [N,K]\n",
    "    proto  = det['proto'].detach().cpu().float()# [H',W',K]  (256,256,K)\n",
    "\n",
    "    # 상위 N 선택\n",
    "    keep = torch.nonzero(scores >= score_thr).squeeze(1)\n",
    "    if keep.numel() == 0:\n",
    "        print(\"No det above score_thr.\")\n",
    "        return\n",
    "    keep = keep[:top_k]\n",
    "    boxes = boxes[keep]\n",
    "    scores_k = scores[keep]\n",
    "    classes_k = classes[keep]\n",
    "    coeff_k = coeff[keep]           # [n,K]\n",
    "\n",
    "    # lincomb + sigmoid\n",
    "    # proto: [H',W',K], coeff: [n,K]\n",
    "    Hs, Ws, K = proto.shape\n",
    "    m_small = torch.einsum('hwk,nk->nhw', proto, coeff_k)  # [n,H',W']\n",
    "    m_prob  = torch.sigmoid(m_small)                       # [n,H',W']\n",
    "\n",
    "    # 업샘플 → [n,1,H,W]\n",
    "    m_up = F.interpolate(m_prob.unsqueeze(1), size=(H, W), mode='bilinear', align_corners=False).squeeze(1)  # [n,H,W]\n",
    "\n",
    "    # 크롭 (xyxy가 0~1 기준이라 가정)\n",
    "    masks_bin = []\n",
    "    for i, box in enumerate(boxes):\n",
    "        x1,y1,x2,y2 = box\n",
    "        # 정규화→픽셀좌표\n",
    "        x1 = int((x1.item())*W) if x1<=1.0 else int(x1.item())\n",
    "        x2 = int((x2.item())*W) if x2<=1.0 else int(x2.item())\n",
    "        y1 = int((y1.item())*H) if y1<=1.0 else int(y1.item())\n",
    "        y2 = int((y2.item())*H) if y2<=1.0 else int(y2.item())\n",
    "        x1,x2 = max(0,x1), min(W,x2)\n",
    "        y1,y2 = max(0,y1), min(H,y2)\n",
    "\n",
    "        m = m_up[i].clone()\n",
    "        # (선택) pred box 바깥은 0으로 마스킹\n",
    "        if x2>x1 and y2>y1:\n",
    "            pad = torch.zeros_like(m)\n",
    "            pad[y1:y2, x1:x2] = m[y1:y2, x1:x2]\n",
    "            m = pad\n",
    "        m = (m > bin_thr).to(torch.uint8)  # 이진화\n",
    "        masks_bin.append(m.numpy())\n",
    "    masks_bin = np.stack(masks_bin, 0)  # [n,H,W]\n",
    "\n",
    "    # GT 준비\n",
    "    if isinstance(gt_masks, torch.Tensor):\n",
    "        gt = (gt_masks.detach().cpu().float() > 0.5).numpy()\n",
    "        if gt.ndim==2: gt = gt[None,...]\n",
    "    else:\n",
    "        gt = np.asarray(gt_masks)\n",
    "        if gt.ndim==2: gt = gt[None,...]\n",
    "\n",
    "    # IoU 간단 샘플\n",
    "    def iou(a,b):\n",
    "        inter = np.logical_and(a,b).sum()\n",
    "        union = np.logical_or(a,b).sum()\n",
    "        return (inter/union) if union>0 else 0.0\n",
    "\n",
    "    print(f\"[DEBUG] masks_bin: shape={masks_bin.shape}, nonzero_total={(masks_bin>0).sum()}\")\n",
    "    n = min(masks_bin.shape[0], gt.shape[0], 5)\n",
    "    for i in range(n):\n",
    "        print(f\"  - pair#{i} IoU={iou(masks_bin[i], gt[i]):.4f} (score={float(scores_k[i]):.3f})\")\n",
    "\n",
    "# 먼저 기본 임계치로\n",
    "compose_masks_with_sigmoid_and_crop(model, dataset, idx=0, score_thr=0.05, bin_thr=0.5, top_k=5)\n",
    "# 그리고 조금 더 느슨하게 (임시로 마스크 이진화 임계치 낮춰 보기)\n",
    "compose_masks_with_sigmoid_and_crop(model, dataset, idx=0, score_thr=0.05, bin_thr=0.3, top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25719136",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but got mat2 is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA_bmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# 패치 후 sanity\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutput_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m postprocess\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m out = \u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbin_thr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpostprocess patched output is None?\u001b[39m\u001b[33m\"\u001b[39m , out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mpostprocess_patched\u001b[39m\u001b[34m(det_output, w, h, batch_idx, interpolation_mode, visualize_lincomb, crop_masks, score_threshold, bin_thr)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# 3) lincomb + sigmoid\u001b[39;00m\n\u001b[32m     43\u001b[39m Hs, Ws, K = proto.shape\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m m_small = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhwk,nk->nhw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoeff\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [n,H',W']\u001b[39;00m\n\u001b[32m     45\u001b[39m m_prob  = torch.sigmoid(m_small)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# 4) 업샘플\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.yolaVenv/lib/python3.12/site-packages/torch/functional.py:422\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, *_operands)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) <= \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum.enabled:\n\u001b[32m    420\u001b[39m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[32m    421\u001b[39m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    424\u001b[39m path = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum.is_available():\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but got mat2 is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA_bmm)"
     ]
    }
   ],
   "source": [
    "import types\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import layers.output_utils as ou\n",
    "\n",
    "def postprocess_patched(det_output, w, h, batch_idx=0, interpolation_mode='bilinear',\n",
    "                        visualize_lincomb=False, crop_masks=True, score_threshold=0.05, bin_thr=0.5):\n",
    "    \"\"\"\n",
    "    - 당신 포크의 구조( dict{'net':..., 'detection': {...}} )를 그대로 지원\n",
    "    - lincomb 후 sigmoid 적용을 보장하고, bin_thr로 이진화\n",
    "    - 매우 단순화(속성/옵션 최소화); 정확한 정합은 프로젝트 postprocess를 참고해 반영\n",
    "    \"\"\"\n",
    "    # 1) 입력 정규화\n",
    "    if isinstance(det_output, (list, tuple)) and len(det_output)>0 and isinstance(det_output[0], dict):\n",
    "        dd = det_output[0]\n",
    "    elif isinstance(det_output, dict) and 'detection' in det_output:\n",
    "        dd = det_output\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    net = dd['net'] if 'net' in dd else None\n",
    "    det = dd['detection'] if 'detection' in dd else dd\n",
    "\n",
    "    boxes  = det.get('box', None)      # [N,4] (0~1 xyxy라고 가정)\n",
    "    scores = det.get('score', None)    # [N]\n",
    "    classes= det.get('class', None)    # [N]\n",
    "    coeff  = det.get('mask', None)     # [N,K]\n",
    "    proto  = det.get('proto', None)    # [H',W',K]\n",
    "\n",
    "    if any(x is None for x in [boxes, scores, classes, coeff, proto]):\n",
    "        return None\n",
    "    if len(scores)==0:\n",
    "        return None\n",
    "\n",
    "    # 2) 상위 score 필터\n",
    "    keep = torch.nonzero(scores >= score_threshold).squeeze(1)\n",
    "    if keep.numel()==0:\n",
    "        return None\n",
    "    boxes, scores, classes, coeff = boxes[keep], scores[keep], classes[keep], coeff[keep]\n",
    "\n",
    "    # 3) lincomb + sigmoid\n",
    "    Hs, Ws, K = proto.shape\n",
    "    m_small = torch.einsum('hwk,nk->nhw', proto, coeff.float().cpu())  # [n,H',W']\n",
    "    m_prob  = torch.sigmoid(m_small)\n",
    "\n",
    "    # 4) 업샘플\n",
    "    m_up = F.interpolate(m_prob.unsqueeze(1), size=(h, w), mode=interpolation_mode, align_corners=False).squeeze(1)  # [n,H,W]\n",
    "\n",
    "    # 5) pred box 바깥 0 (crop)\n",
    "    if crop_masks:\n",
    "        m_up_np = m_up.clone()\n",
    "        for i, box in enumerate(boxes):\n",
    "            x1,y1,x2,y2 = box\n",
    "            # 정규화 좌표 가정 → 픽셀로\n",
    "            x1 = int((x1.item())*w) if x1<=1.0 else int(x1.item())\n",
    "            x2 = int((x2.item())*w) if x2<=1.0 else int(x2.item())\n",
    "            y1 = int((y1.item())*h) if y1<=1.0 else int(y1.item())\n",
    "            y2 = int((y2.item())*h) if y2<=1.0 else int(y2.item())\n",
    "            x1,x2 = max(0,x1), min(w,x2); y1,y2 = max(0,y1), min(h,y2)\n",
    "            pad = torch.zeros_like(m_up_np[i])\n",
    "            if x2>x1 and y2>y1:\n",
    "                pad[y1:y2, x1:x2] = m_up_np[i][y1:y2, x1:x2]\n",
    "            m_up[i] = pad\n",
    "\n",
    "    # 6) 이진화\n",
    "    m_bin = (m_up > bin_thr)\n",
    "\n",
    "    # 출력 포맷 맞추기: (classes, scores, boxes, masks)\n",
    "    return (classes.cpu(), scores.cpu(), boxes.cpu(), m_bin.cpu())\n",
    "\n",
    "# monkey patch\n",
    "ou.postprocess = postprocess_patched\n",
    "\n",
    "# 패치 후 sanity\n",
    "from layers.output_utils import postprocess\n",
    "out = postprocess(model(dataset[0][0].unsqueeze(0).to(device())), dataset[0][0].shape[2], dataset[0][0].shape[1],\n",
    "                  score_threshold=0.05, bin_thr=0.5)\n",
    "print(\"postprocess patched output is None?\" , out is None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8e48732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ postprocess patched (device fix + sigmoid + configurable bin_thr)\n",
      "None? False\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn.functional as F\n",
    "from layers.output_utils import sanitize_coordinates, crop\n",
    "import layers.output_utils as ou\n",
    "\n",
    "def postprocess_patched(det_output, w, h, batch_idx=0, interpolation_mode='bilinear',\n",
    "                        visualize_lincomb=False, crop_masks=True, score_threshold=0.05, bin_thr=0.5):\n",
    "    # det_output은 [{'net':..., 'detection': {...}}] 형태\n",
    "    dets = det_output[batch_idx]\n",
    "    net = dets['net']\n",
    "    dets = dets['detection']\n",
    "    if dets is None:\n",
    "        return [torch.Tensor()] * 4\n",
    "\n",
    "    if score_threshold > 0:\n",
    "        keep = dets['score'] > score_threshold\n",
    "        for k in dets:\n",
    "            if k != 'proto':\n",
    "                dets[k] = dets[k][keep]\n",
    "        if dets['score'].size(0) == 0:\n",
    "            return [torch.Tensor()] * 4\n",
    "\n",
    "    classes = dets['class']\n",
    "    boxes   = dets['box']\n",
    "    scores  = dets['score']\n",
    "    coeff   = dets['mask']     # [N,K]\n",
    "    proto   = dets['proto']    # [H',W',K]\n",
    "\n",
    "    # --- 디바이스 맞추기 ---\n",
    "    dev = proto.device\n",
    "    coeff = coeff.to(dev)\n",
    "    boxes = boxes.to(dev)\n",
    "\n",
    "    # lincomb + sigmoid (활성화 보장)\n",
    "    masks = torch.einsum('hwk,nk->nhw', proto, coeff.float())  # [n,H',W']\n",
    "    masks = torch.sigmoid(masks)\n",
    "\n",
    "    # crop (box는 보통 정규화; sanitize는 아래에서)\n",
    "    if crop_masks:\n",
    "        masks_c = masks.permute(1,2,0).contiguous()   # [H',W',n]\n",
    "        masks_c = crop(masks_c, boxes)                # [H',W',n]\n",
    "        masks   = masks_c.permute(2,0,1).contiguous() # [n,H',W']\n",
    "\n",
    "    # 업샘플\n",
    "    masks = F.interpolate(masks.unsqueeze(1), (h, w), mode=interpolation_mode, align_corners=False).squeeze(1)  # [n,H,W]\n",
    "\n",
    "    # 이진화\n",
    "    masks = masks.gt(bin_thr)\n",
    "\n",
    "    # boxes sanitize (마스크 출력과 무관하지만 원 코드 흐름 유지)\n",
    "    boxes = boxes.clone()\n",
    "    boxes[:, 0], boxes[:, 2] = sanitize_coordinates(boxes[:, 0], boxes[:, 2], w, cast=False)\n",
    "    boxes[:, 1], boxes[:, 3] = sanitize_coordinates(boxes[:, 1], boxes[:, 3], h, cast=False)\n",
    "    boxes = boxes.long()\n",
    "\n",
    "    return classes.cpu(), scores.cpu(), boxes.cpu(), masks.cpu()\n",
    "\n",
    "ou.postprocess = postprocess_patched\n",
    "print(\"✅ postprocess patched (device fix + sigmoid + configurable bin_thr)\")\n",
    "\n",
    "# 간단 sanity\n",
    "img0, _ = dataset[0]\n",
    "out = ou.postprocess(model(img0.unsqueeze(0).to(device())), img0.shape[2], img0.shape[1],\n",
    "                     score_threshold=0.05, bin_thr=0.3)\n",
    "print(\"None?\", out is None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae04fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".yolaVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
